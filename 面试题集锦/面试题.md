1.TreeSet和HashSet的区别

    ans:两者主要在实现方式 数据是否有序,以及是否可以放入null值等三方面存在区别
    
    **一.实现方式**
    a.HashSet底层采用HashMap,也就是hash表实现
    b.TreeSet底层采用TreeMap,也就是红黑树实现

    **二.数据是否有序**
    HashSet中的数据是无序的
    TreeSet中数据可以根据自然排序Comparable和比较排序Comparator进行排序
    
    **三.是否可以放入null值**
    HashSet可以放入null,但是只能放入null,(key==null,key键的hash值将为0,HashMap使用第0个桶存放键为null的键值对)  
    而TreeSet不允许放入null(无法进行比较)

2.HashMap如何解决冲突,扩容机制

    HashMap是基于哈希表的数据结构实现的
    常用的数据结构:数组 链表 哈希表 树
    哈希表将键的hash值映射到内存地址,也就是说HashMap是根据键的Hash值来决定对应值的存储位置.通过这种索引方式,HashMap获取数据的速度会非常快.
    两个对象的存储地址冲突,这种现象被称为哈希冲突,哈希表是怎么解决的呢?开放地址法 再哈希函数法和链地址法
    
    **开放地址法**:当发生哈希冲突时,如果哈希表未被装满,说明在哈希表中必然还有空位置,那么可以把key存放到冲突位置后面的空位置上去.这种方法存在着很多
    缺点,例如查找 扩容.所以不建议作为解决哈希冲突的首选
    
    **再哈希法**:在同一词产生地址冲突时再计算另一个哈希函数地址,直到冲突不再发生,这种方法不易产生"聚集",但却增加了计算时间,如果不考虑增加元素的时间,  
    且对查询元素的要求极高,就可以考虑使用这种算法设计.
    
    **链地址法**:这种方法时采用了数组(哈希表)+链表的数据结构,当发生哈希冲突时,就用一个链表结构存储相同hash值的数据
    
HashMap的重要属性**:HashMap是由一个Node数组构成,每个Node包含了一个key-value键值对.
```java
public class HashMap{
    transient Node<K,V>[] table;
    int threshold;// 边界值
    final float loadFactor;// 加载因子
    
    static class Node<K,V> implements Map.Entry<K,V>{
        final int hash;
        final K key;
        V value;
        Node<K,V> next;
         Node(int hash, K key, V value, Node<K,V> next) { 
             this.hash = hash;          
             this.key = key;           
             this.value = value;        
             this.next = next;      
         }
    }
}
```

HashMap添加元素优化:
```java
public class HashMap{
 public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
  
 static final int hash(Object key) {
        int h;
        // (h = key.hashCode()) ^ (h >>> 16)尽量打乱hashcode真正参与运算的低16位
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    } 
  void put(){
  if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        //通过putVal方法中的(n - 1) & hash决定该Node的存储位置
        // (n - 1) & hash,n为2的n次方,这样恰好可以保证计算得到的索引值总是位于table数组的索引之内
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
  }  
}
```
put方法流程:

![image_17](../image_17.png)

    1.开始put
    2.判断table为null或者tab的长度为0时,通过resize()方法得到初始化table
    3.通过(n - 1) & hash计算出的值作为tab的下标i,并判断该下标i的节点是否为null
    4.如果3为true,则new第一个Node节点,调用newNode方法返回新节点赋值给tab[i]
    5.如果3为false,则分为三种情况处理
        a.如果存在相等key值的节点,HashMap中判断是否存在key和插入的key相等,如果相等,则将存在key值的Node覆盖
        b.判断新增节点是否为红黑树节点,如果是则新增红黑树节点
        c.轮询新增节点所在的链表长度,判断长度是否超过TREEIFY_THRESHOLD
        c1.如果超过,则将链表转为红黑树,否则在链表尾部新增Node节点

```java

public class HashMap{
    /**
     * Associates the specified value with the specified key in this map.
     * If the map previously contained a mapping for the key, the old
     * value is replaced.
     *
     * @param key key with which the specified value is to be associated
     * @param value value to be associated with the specified key
     * @return the previous value associated with <tt>key</tt>, or
     *         <tt>null</tt> if there was no mapping for <tt>key</tt>.
     *         (A <tt>null</tt> return can also indicate that the map
     *         previously associated <tt>null</tt> with <tt>key</tt>.)
     */
    public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
    /**
     * Implements Map.put and related methods
     *
     * @param hash hash for key
     * @param key the key
     * @param value the value to put
     * @param onlyIfAbsent if true, don't change existing value
     * @param evict if false, the table is in creation mode.
     * @return previous value, or null if none
     */
 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
        //1、判断当table为null或者tab的长度为0时，即table尚未初始化，此时通过resize()方法得到初始化的table
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) & hash]) == null)
        //1.1、此处通过（n - 1） & hash 计算出的值作为tab的下标i，并另p表示tab[i]，也就是该链表第一个节点的位置。并判断p是否为null
            tab[i] = newNode(hash, key, value, null);
        //1.1.1、当p为null时，表明tab[i]上没有任何元素，那么接下来就new第一个Node节点，调用newNode方法返回新节点赋值给tab[i]
        else {
        //2.1下面进入p不为null的情况，有三种情况：p为链表节点；p为红黑树节点；p是链表节点但长度为临界长度TREEIFY_THRESHOLD，再插入任何元素就要变成红黑树了。
            Node<K,V> e; K k;
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
        //2.1.1HashMap中判断key相同的条件是key的hash相同，并且符合equals方法。这里判断了p.key是否和插入的key相等，如果相等，则将p的引用赋给e
                e = p;
            else if (p instanceof TreeNode)
        //2.1.2现在开始了第一种情况，p是红黑树节点，那么肯定插入后仍然是红黑树节点，所以我们直接强制转型p后调用TreeNode.putTreeVal方法，返回的引用赋给e
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
        //2.1.3接下里就是p为链表节点的情形，也就是上述说的另外两类情况：插入后还是链表/插入后转红黑树。另外，上行转型代码也说明了TreeNode是Node的一个子类
                for (int binCount = 0; ; ++binCount) {
        //我们需要一个计数器来计算当前链表的元素个数，并遍历链表，binCount就是这个计数器

                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) 
        // 插入成功后，要判断是否需要转换为红黑树，因为插入后链表长度加1，而binCount并不包含新节点，所以判断时要将临界阈值减1
                            treeifyBin(tab, hash);
        //当新长度满足转换条件时，调用treeifyBin方法，将该链表转换为红黑树
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }e, boolean onlyIfAbsent,boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
        //1、判断当table为null或者tab的长度为0时，即table尚未初始化，此时通过resize()方法得到初始化的table
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) & hash]) == null)
        //1.1、此处通过（n - 1） & hash 计算出的值作为tab的下标i，并另p表示tab[i]，也就是该链表第一个节点的位置。并判断p是否为null
            tab[i] = newNode(hash, key, value, null);
        //1.1.1、当p为null时，表明tab[i]上没有任何元素，那么接下来就new第一个Node节点，调用newNode方法返回新节点赋值给tab[i]
        else {
        //2.1下面进入p不为null的情况，有三种情况：p为链表节点；p为红黑树节点；p是链表节点但长度为临界长度TREEIFY_THRESHOLD，再插入任何元素就要变成红黑树了。
            Node<K,V> e; K k;
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
        //2.1.1HashMap中判断key相同的条件是key的hash相同，并且符合equals方法。这里判断了p.key是否和插入的key相等，如果相等，则将p的引用赋给e
                e = p;
            else if (p instanceof TreeNode)
        //2.1.2现在开始了第一种情况，p是红黑树节点，那么肯定插入后仍然是红黑树节点，所以我们直接强制转型p后调用TreeNode.putTreeVal方法，返回的引用赋给e
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
        //2.1.3接下里就是p为链表节点的情形，也就是上述说的另外两类情况：插入后还是链表/插入后转红黑树。另外，上行转型代码也说明了TreeNode是Node的一个子类
                for (int binCount = 0; ; ++binCount) {
        //我们需要一个计数器来计算当前链表的元素个数，并遍历链表，binCount就是这个计数器

                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) 
        // 插入成功后，要判断是否需要转换为红黑树，因为插入后链表长度加1，而binCount并不包含新节点，所以判断时要将临界阈值减1
                            treeifyBin(tab, hash);
        //当新长度满足转换条件时，调用treeifyBin方法，将该链表转换为红黑树
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
}
```
HashMap获取元素优化:

    当HashMap中只存在数组,而数组中没有Node链表时,是HashMap查询性能最好的时候.一旦
    发生大量的哈希冲突,就会产生Node链表,这个时候每次查询元素都可能遍历Node链表,从而降低查询数据的性能.特别是在链表
    长度过长的情况下,性能将明显降低,红黑树的使用很好的解决了这个问题,使得查询的平均复杂度降低到了O(log(n)),链表越长,
    使用红黑树替换后的查询效率提升就越明显.
    
HashMap扩容优化:

    在jdk1.8中,HashMap对扩容操作做了优化.由于扩容数组的长度是2倍关系,所以对于假设初始tableSize=4
    要扩容到8来说,就是0100到1000的变化,在扩容中只用判断原来的hash值和左移动的一位(newTable的值)按位与操作是0或1就行,
    0的话索引不便,1的话索引变成原索引加上扩容前数组.
    之所以呢能通过这种"与运算"来重新分配索引,是因为hash值本来就是随机的,而hash按位与上newTable得到的0(扩容前的索引位置)和1(扩容前的索引位置加上扩容前数组长度的数值索引处)
    就是随机的,所以扩容的过程就能把之前哈希冲突的元素再随机分布到不同的索引中去
    
链地址法:

    这种方法的基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，  
    因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。


3.ConcurrentHashMap如何做到高并发的?

    为什么需要CHM?
    一是因为HashTable本身比较低效,因为它的实现基本就是将put get size等各种方法加上synchronized.简单来说,这就导致了
    所有并发操作都要竞争同一把锁,一个线程在进行同步操作时,其他线程只能等待,大大降低了并发操作的效率
    
    二是HashMap不支持线程的同步，即任一时刻可以有多个线程同时写HashMap;可能会导致数据的不一致
    
    三能不能利用Collections提供的同步包装器来解决问题?同步包装器只是利用输入Map够早了另一个同步版本,所有操作虽然不再声明称为
     synchronized方法,但是还是利用了"this"作为互斥的mutex,没有真正意义上的改进
```java

private static class SynchronizedMap<K,V>
    implements Map<K,V>, Serializable {
    private final Map<K,V> m;     // Backing Map
    final Object      mutex;        // Object on which to synchronize
    // …
    public int size() {
        synchronized (mutex) {return m.size();}
    }
 // 
}
```
所以，Hashtable 或者同步包装版本，都只是适合在非高度并发的场景下

CHM1.7与1.8比较:

    1.7
    put加锁,
    通过分段加锁segment,一个hashmap里有若干个segment,每个segment里有若干个桶,
    桶里存放k-V形式的链表,put数据时通过key哈希得到该元素要添加的segment,然后对segment
    进行加锁,然后在哈希,计算得到给元素要添加到的桶,然后遍历桶中的链表,替换或新增节点到桶中
    
    size:分段计算两次
    
    1.8
    put CAS加锁
    1.8中不依赖与segment加锁,segment数量与桶数量一致
    首先判断容器是否为空,为空则进行初始化,
    initTable()利用volatile的sizeCtl作为互斥手段,如果发现竞争性的初始化,就暂停
    在哪里,等待条件恢复;
    否则初始化时利用CAS设置排他标志sizeCtl;
    否则重试初始化;
    如果容器不为空但节点bin是空的,则利用CAS去进行无锁操作线程
    对key hash计算得到该key存放的的桶位置,判断该桶是否为空,为空则利用CAS设置新节点;
    否则使用synchronized加锁,遍历桶中数据,替换桶中数据,替换或新增加点到桶中;
    最后判断是否需要转为红黑树,转换之前判断是否需要扩容
    
    size:利用LongAdd累计计算
    
    put方法流程
    1.首先判断容器是否为空,为空则进行初始化initTable()
    2.如果容器不为空,但是根据tabAt(table,(n-1)&hash))==null,为true,则利用CAS进行无锁操作,对key进行hash计算
    得到key存放的桶位置,判断该桶是否为空,为空则利用CAS设置新节点
    3.根据tabAt(table,(n-1)&hash))==null,为false,(fh = f.hash) == MOVED为true,则当前线程帮助搬移数据
    4.如果以上都不是,则使用synchronized对该节点加锁,遍历通中数据,替换桶中数据,新增加节点到数据

```java
public class ConcurrentHashMap{
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    break;                   // no lock when adding to empty bin
            }
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key,
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }
    private final Node<K,V>[] initTable() {
        Node<K,V>[] tab; int sc;
        while ((tab = table) == null || tab.length == 0) {
            if ((sc = sizeCtl) < 0)
                Thread.yield(); // lost initialization race; just spin
            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    if ((tab = table) == null || tab.length == 0) {
                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                        @SuppressWarnings("unchecked")
                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                        table = tab = nt;
                        sc = n - (n >>> 2);
                    }
                } finally {
                    sizeCtl = sc;
                }
                break;
            }
        }
        return tab;
    }
}
```

    **initTable流程**
    利用volatile的sizeCtl作为互斥手段,如果发现竞争性的初始化,就暂停在哪里,等待条件恢复;
    否则初始化时利用CAS设置排他标志sizeCtl;
    否则重试初始化;
    白话解释下:从源码中可以看出table的初始化在一个cas方法中进行,当table为null或者长度为0时,进入之后判断
    sizeCtl的值,如果sizeCtl<0则线程让步,由于初始化状态sizeCtl是等于0的,说明前面已经有线程进入了else if这部分,
    将sizeCtl的值置为-1,表示正在初始化


4.线程池平常怎么用

    线程池原理:在线程池内部,维护了一个阻塞队列workQueue和一组工作线程,工作线程的个数由构造函数中的poolsize来指定.
    用户通过调用execut()方法来提交Runnable任务,execute()方法的内部实现仅仅是将任务加入到workQueue中.线程池内部维护的
    工作线程会消费WorkQueue中的任务并执行任务.

```java
//简化的线程池，仅用来说明工作原理
class MyThreadPool{
  //利用阻塞队列实现生产者-消费者模式
  BlockingQueue<Runnable> workQueue;
  //保存内部工作线程
  List<WorkerThread> threads = new ArrayList<>();
  // 构造方法
  MyThreadPool(int poolSize, BlockingQueue<Runnable> workQueue){
    this.workQueue = workQueue;
    // 创建工作线程
    for(int idx=0; idx<poolSize; idx++){
      WorkerThread work = new WorkerThread();
      work.start();
      threads.add(work);
    }
  }
  // 提交任务
  void execute(Runnable command){
    workQueue.put(command);
  }
  // 工作线程负责消费任务，并执行任务
  class WorkerThread extends Thread{
    public void run() {
      //循环取任务并执行
      while(true){ 
        Runnable task = workQueue.take();
        task.run();
      } 
    }
  }
/** 下面是使用示例 **/
public static void main(String[] args) {
    // 创建有界阻塞队列
    BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue<>(2);
    // 创建线程池  
    MyThreadPool pool = new MyThreadPool(10, workQueue);
    // 提交任务  
    pool.execute(()->{System.out.println("hello"); });
  }
}
```
线程应用的场景:

    普通的场景,使用工厂类Executors创建就可以了.常见的有fix Single cache三种,更多时候,为了更精细的控制,会直接对ThreadPoolExecutor类进行定制,我尤其关系其中的阻塞队列和饱和策略
线程池拒绝策略:

        CallerRunsPolicy:提交任务的线程自己去执行该任务
        AbortPolicy:默认的拒绝策略,会抛出异常
        DiscardPolicy:直接丢弃任务,没有异常
        DiscardOldestPolicy:丢弃最老的任务

线程池参数介绍:把线程池类比为一个项目组,而线程就是项目组中的成员
```java
public class ThreadPoolExecutor{
    ThreadPoolExecutor(
      int corePoolSize,// 表示线程池保有的最小线程数.有些项目很闲,但是也不能把人都撤了,至少要保留corePoolSize个人坚守阵地
      int maximumPoolSize,// 表示线程池创建的最大线程数.当项目很忙时,就需要家加人,但是也不能无限加,最多加到maximumPoolSize个人
      long keepAliveTime,// 项目根据忙闲开增减人员,在编程世界里,如何定义忙和闲呢?一个线程如果在一段时间内,都没有执行任务,说明很闲,
      TimeUnit unit,// keepAliveTime&unit就是用来定义这个"一段时间"的参数,也就是说一个线程空闲了keepAliveTime&unit了这么久,而且线程池的线程数大于corePoolSize,na那么这个空闲的线程就要被回收了
      BlockingQueue<Runnable> workQueue,// 工作队列
      ThreadFactory threadFactory,//通过这个参数可以自定义如何创建线程,例如可以给线程指定一个有意义的名字
      RejectedExecutionHandler handler); //通过这个参数可以自定义任务的拒绝策略.如果线程池中所有的线程都在忙碌,并且工作队列也满了,前提是工作队列是有界队列,name
      // 此时提交任务,线程池就会拒绝接收
  }
```

```java
public class Executors{
    public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
     public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>(),
                                      threadFactory);
    }
    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }
}
```
5.多个线程等到某一节点然后统一放行有几种实现方式?

    **CountDownLatch**:  
    主要用来解决一个线程等待多个线程的场景,可以类比旅游团团长要等待所有的游客到齐才能去下一个景点,
    主线程阻塞在await方法,每个线程调用countDown()
    **CyclicBarrier**: 是一组线程之间互相等待,更像是几个驴友之间不离不弃,每个线程阻塞在await上,达到一定阈值集体放行
    **Future**:实现线程之间的等待

6.数据库索引结构?

    哈希表 有序数组 搜索树
    哈希表这种结构适用于等值查询的场景(处理冲突的方式是链表)
    有序数组在等值查询和范围查询场景中的性能都很非常优秀,优点:查询效率高,缺点:插入一条记录成本高
    有序数组索引只适用静态存储引擎
    二叉搜索树

7.select * from t where a=? and b>? order by c limit 0,100如何加索引

8.什么是聚簇索引和非聚簇索引?

    主键索引的叶子节点存的是整行数据,在InnoDB中,主键索引被称为聚簇索引
    非主键索引的叶子节点内容是主键的值,在InnoDB中,非主键索引也被称为二级索引,也被称为非聚簇索引
    基于主键索引和普通索引的查询有什么区别?
    如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；  
    如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。  
    这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

9.了解CAP吗?redis里的CAP是怎样的?
    a.什么是CAP?

    结合电商的例子,理解CAP的含义?
    假设某电商在北京 杭州 上海三个城市建立了仓库,同时建立了对应的服务器A B C,用于存储商品信息.比如,某电吹风在北京仓库有20个,在杭州仓库
     有10个,在上海仓库有30个.那么,CAP这三个字母在这个例子中分别代表什么呢?
    C 代表Consistency,一致性,是指所有节点在同一时刻的数据时相同的,即更新操作执行结束并响应用户完成后,所有节点存储的数据会保持相同.
    在电商系统中,A B C 中存储的该电吹风的数量应该是20+10+30=60.假设,现在有一个北京用户买走一个电吹风,服务器A会更新数据为60-1=59,
    与此同时要求B和C也更新为59,以保证在同一时刻,无论访问A B C 中的哪个服务器,得到的数据均是59;
    A代表Availability,可用性,是指系统提供的服务一直处于可用状态,对于用户的请求可即时响应
    在电商系统中,用户在任一时刻向A B C中的任一服务器发出请求时,均可得到即时响应,比如查询商品信息等.
    P代表Partition Tolerance,分区容错性,是指在分布式系统遇到网路分区的情况下,仍然可以响应用户的请求.网络分区是指因为网络故障不连通,不同节点分布在不同的子网络
    中,各个子网络内网络正常.
    在电商系统中,假设C和A B的网络都不通了,A和B是相通的.也就是说,形成了两个分区{A,B}和{C},在这种情况下,系统仍能响应用户请求.
    一致性 可用性 分区容错性是分布式系统的三个特征,那么我们平时所说的CAP理论又是什么呢?

CAP理论指的就是在分布式系统中C A P这三个特征不能同时满足,只能满足其中两个
![image_10](../image_10.png)

    对这个系统来说.分别满足C A P指的是
    在满足一致性C的情况下,Server1和Server2中的数据库始终保持一致,即DB1和DB2内容要始终保持相同
    在满足可用性A的情况下,用户无论访问Server1还是Server2,都会得到即时响应;
    在满足分区容错性P的情况下,Server1和Server2之间即使出现网路故障也不会影响Server1和Server2分别处理用户的请求

    在实际场景中,网络环境不可能100%不出故障,比如网络拥塞 网卡故障等,会导致网络故障或不通,从而导致节点之间无法通信,
    或者集群中节点被划分为多个分区,分区中节点之间可通信,分区间不可通信,这种由网络故障导致的集群分区情况,被称为"网络分区"

    在分布式系统中,网络分区不可避免,因此分区容错性P必须满足.
    在满足分区容错性P的情况下,一致性C和可用性A是否可以同时满足
    User2向Server2发送读取数据a的请求时,Server2无法给用户返回最新数据,那么该如何处理呢?
    第一种处理方式,保证一致性C,牺牲可用性A:Server2选择让User2的请求阻塞,一直等到网络恢复正常,Server1被修改的数据同步更新
    到Server2之后,即DB2中数据a修改成最新值2后,再给用户User2响应;
    第二种处理方式是,保证可用性A,牺牲一致性C:Server2选择将旧的数据a=1返回给用户,等到网络恢复,再进行数据同步
    除了以上这两种方案,没有其他方案可以选择,可以看出:在满足分区容错性P的前提下,一致性C和可用性A只能选择一个,无法同时满足;

CAP的选择策略和应用,在无法同时满足CAP这三个特性,那该如何进行取舍呢?

    其实,C A P,没有谁优谁劣,只是不同的分布式场景适合不同的策略,接下来,针对一些场景为例,分别于你介绍CA弃P 保CP弃A
    保AP弃C这三种策略,分析面对不同的分布式场景时,知道如何权衡这三个特征.
    
    保 CA 弃 P
    在分布式系统中,现在的网络基础设施无法做到始终保持稳定,网络分区难易避免,牺牲分区容错性,就相当于放弃使用分布式系统.因此
    在分布式系统中,这种策略不需要过多讨论.
    
    既然分布式系统不能采用这种策略,那单点系统毫无疑问就需要满足CA特性了,比如关系型数据库部署在单台机器上,因此不存在网络通信问题,所以保证CA就可以了
    
    保 CP 弃 A
    如果一个分布式场景需要很强的数据一致性,或者该场景可以容忍系统长时间无响应的情况下,保CP弃A这个策略就比较合适
    一个保证CP而舍弃A的分布式系统,一旦发生网络分区会导致无法同步情况,就要牺牲系统的可用性,降低用户体验,直到节点数据达到一致后再响应用户.
    这种策略通常用在涉及金钱交易的分布式场景下,因为它任何时候都不允许出现数据不一致的情况,否则就会给用户造成损失.因此这种场景下必须保证CP
    保证CP的系统有很多,典型的有Redis Hbase Zookeeper.
    以zookeeper为例,带你了解它是如何保证CP的
    下面是zookeeper的架构图
    ![image_11](../image_11.png)
    zookeeper集群包含多个节点(Server),这些节点会通过分布式选举算法选出一个Leader节点.在Zookeeper中选举Leader节点采用的是ZAB算法
    在Zookeeper集群中,Leader节点之外的节点被称为Follower节点,Leader节点会专门负责处理用户的写请求:
    当用户想节点发送写请求的时候,如果请求的节点刚好是Leader,那就直接处理该请求;
    如果请求的是follower节点,那该节点会将请求转给Leader,然后Leader会先向所有的Follower发出一个Proposal,等超过一半的节点同意后,
    Leader才会提交这次写操作,从而保证了数据的一致性.
    当出现网络分区时,如果其中一个分区的节点数大于集群总节点数的一半,那么这个分区可以再选出一个Leader,仍然对用户提供服务,但在选出Leader
    之前,不能正常为用户提供服务;如果形成的分区中,没有一分区的节点数大于集群总节点数的一半,那么系统不能正常为用户提供服务,必须待网络恢复后,  
    才能正常提供服务.
    这种设计方式保证了分区容错性,但是牺牲了一定的系统可用性;
    
    保AP弃C
    如果一个分布式场景需要很高的可用性,或者说在网络状况不太好的情况下,该场景允许数据暂时不一致,那这种情况下就可以牺牲一定的一致性了.
    网络分区出现后,各个节点之间数据无法马上同步,为了保证高可用,分布式系统需要即刻响应用户的请求.但是此时可能某些节点还没有拿到最新数据,只能将本地旧的数据  
    返回给用户,从而导致数据不一致的情况.
    适合保证AP放弃C的场景有很多.比如,很多查询网站 电商系统中的商品查询等,用户体验非常重要,所以大多会保证系统的可用性,而牺牲一定的数据一致性;

 三种策略的对比
![image_12](../image_12.png)

CAP和ACID的"C" "A"是一样的吗?
    首先看C:
    CAP中的C强调的是数据一致性,也就是集群中节点之间通过复制技术保证每个节点上数据在同一时刻是相同的;
    ACID中的C强调的是事务执行前后,数据的完整性保持一致或满足完整性约束.也就是不管在什么时候,不管并发事务有多少,事务在分布式系统中的状态始终保持一致;
    再来看A:
    CAP中的A指的是可用性Availablity,也就是系统提供的服务一直处于可用状态,即对于用户的请求可即时响应.
    ACID中的A指的是原子性Atomicity,强调的是事务要么执行成功,要么执行失败
    因此,CAP和ACID的C和A是不一样的,不能混为一谈.
    redis简单主从模式侧重于CP的,即对于一致性要求较高.redis-cluster,则属于AP类型,更加强调可用性

BASE理论

10.如何理解幂等?项目中接口的幂等是如何做的?
幂等是指多次执行,影响相同.
> 比如大多数Post操作,重复提交订单等,最终只会有一个订单生成成功.
> 还有一种情况是消息,由于大多数MQ只保证at least once,所以消息有时会重复
> 对于Post请求,一般在请求成功后,强制跳转到其他页面,避免刷新提交.
> 复杂的操作一般使用流水号来实现
> 某些不带流水号的消息,处理的时候,就要进行多次校验,甚至引入消息状态表,来保证幂等

11.算法题:两个有序的list,求交集

-------------------------------------------------

1.解释下乐观锁和悲观锁

    悲观锁总是假设情况最坏,每次操作数据都认为别人会来修改,就加锁来保证安全.后面的访问者只能等待.
    数据库中的行锁 表锁,java中的同步关键字等,都属于悲观锁
    乐观锁正好相反,总是假设最好的情况,不用对数据加锁,但是多了一次额外的判断.比如并发包中大量的CAS操作 判断新旧版本号机制等
    ***悲观锁是老婆,由你独占;乐观锁是炮友,按预约规划***
2.jvm判断对象是否回收?

    一般一个对象不再被引用,就代表该对象可以被回收?目前根据可达性分析算法判断该对象是否可以被回收.
    可达性分析算法:GCRoots是该算法的基础,GCRoots是所有对象的根对象,在jvm加载时,会创建一些普通对象引用正常对象.
    这些对象作为正常对象的起始点,在垃圾回收时,会从这些GCRoots开始向下搜索,当一个对象到GCRoots没有任何引用链相连时,
    就证明此对象是不可用的.
    GCRoots有哪些?
    a.虚拟机栈中引用的对象
    b.本地方法栈中jni引用的对象
    c.方法区中的静态变量和常量引用的对象
    d.活跃线程引用的对象

3.反射能获得类里面方法的名称吗?参数名称呢?参数类型呢?

    都可以.jdk8以后通过Parameter类获取参数名称.但有前提,需要加编译开关
    javac -parameters
    默认是关闭的

4.动态代理的实现方式?cglib和jdk的代理有什么区别?

    1.通过实现InvocationHandler接口创建自己的调用处理器
    2.通过为Proxy类指定ClassLoader对象和一组interface以及自己的调用处理器,来创建动态代理类
    3.通过反射机制获得动态代理类的构造函数,其唯一参数类型是调用处理器接口类型
    4.通过构造函数创建动态代理类实例,构造时调用处理器对象作为参数传入
    
    **jdkProxy的优势**:
        最小化依赖关系,减少依赖意味着简化开发和维护,jdk本身的支持,可能比cglib更加可靠
        平滑进行jdk版本升级,而字节码类库通常需要进行更新以保证在新版java上能够使用
        代码实现更简单
    **CGLib的优势**:  
        有的时候调用目标不便实现额外接口,从某种角度看,限定调用者实现接口是有些侵入性的实践,类似cglib动态代理就没有这种限制  
        只操作我们关心的类,而不必为其他相关类增加工作量  
        高性能  
    **总结**:
        静态代理:事先写好代理类,可以手工编写,也可以用工具生成.缺点是每个业务类都要对应一个代理类,非常不灵活  
        动态代理:运行时自动生成代理对象.缺点是生成代理对象和调用代理方法都要额外花费时间  
            jdk动态代理:基于java反射机制实现,必须要实现了接口的业务类才能用这种办法生成代理对象,新版本也开始结合ASM机制  
            cglib动态代理:基于ASM机制实现,通过生成业务类的子类作为代理类  
            ASM机制:ASM是被设计用于运行时的，离线的类生成和转换，作用于已编译好的Java class，并且被设计的尽可能的小巧快速，  
            其目的是生成、转换和分析以字节数组表示的已编译 Java 类(它们在磁盘中的存储 和在 Java 虚拟机中的加载都采用这种字节数组形式)。  
            为此，ASM 提供了一些工具，使用高于字节级别的概念来读写和转换这种字节数组，这些概念包括数值常数、字符串、Java 标识符、Java  
            类型、Java 类结构元素，等等。注意，ASM 库的范围严格限制于类的读、写、转换和分析。具体来说，类的加载过程就超出了它的范围之外

5.分布式锁有哪些主流实现方式?Redis和zk锁有什么区别?

    大体分为两类
    乐观锁:
        基于版本号机制和CAS实现,与存放版本号的存储无关
    悲观锁:  
        1.基于数据库记录,进入时写数据,退出时删除记录  
        2.数据库行锁,它是一把排他锁  
        3.基于Redis的setNx函数  
        4.基于zookeeper  
        区别:redis获取锁是轮询机制.锁释放后会有多个调用者争抢,某些任务可能会饿死  
        zk是监听机制,有变动会接到通知.除了非公平锁,也可以实现公平锁

6.ThreadLocal作用是什么?说下用法

    ThreadLocal用来隔离数据
    ThreadLocal中存放的是与线程相关的数据,底层实际上是一个map,通过线程可以获取存储数据的相关信息
    一些需要绑定到线程的数据,比如一些线程的统计数据,就可以放在这里

    (java并发编程实战)ThreadLocal的实现里面有一个Map,叫做ThreadLocalMap,不过持有ThreadLocalMap的不是ThreadLocal,
    而是Thread. Thread这个类内部有一个私有属性threadLocals,其类型就是ThreadLocalMap,ThreadLocalMap的key就是是ThreadLocal.
    为何这样设计?
    一是ThreadLocal仅仅是一个代理工具类,内部并不持有任何与线程相关的数据,所有和线程相关的数据都存储在Thread里面,这样的设计更容易理解.
    并且从数据的亲缘性上来讲,ThreadLocalMap属于Thread也更加合理
    二是不容易产生内存泄漏,Thread持有ThreadLocalMap,ThreadLocalMap里对ThreadLocal的引用还是弱引用(WeakReference),
    所以只要Thread对象可以被回收,那么ThreadLocalMap就能被回收
    
    ThreadLocal与内存泄漏
    在线程池中使用ThreadLocal为什么可能导致内存泄漏?
    原因就出在线程池中线程的存活时间太长,往往都是和程序同生共死的,这就意味着Thread持有的ThreadLocalMap一直都不会被回收,
    再加上ThreadLocalMap中的Entry对ThreadLocal是弱引用,所以只要ThreadLocal结束了自己的生命周期是可以被回收掉的,但是Entry中的value
    却是被Entry强引用的,所以即便value的生命周期结束了,value也是无法被回收的,从而导致内存泄漏
    那在线程池中,该如何正确使用ThreadLocal呢?其实很简单,既然jvm不能做到自动释放对value的强引用,那我们手动释放就可以了.如何能做到手动释放呢?
    try{} finally{}方案,手动释放资源利器
    
    ThreadLocal的优化方式FastThreadLocal
    FastThreadLocal使用了单纯的数组来替代ThreadLocal的hash表操作,索引在高并发的情况下,FastThreadLocal更快
    set操作:FastThreadLocal直接根据index进行数组set,而 ThreadLocal 需要先根据ThreadLocal的hashcode计算数组下标,然后
    再根据线性探测法进行set操作,期间如果发生hash冲突且有无效的Entry时,还要进行entry的清理和整理操作.最后不管是否冲突,都要进行
    一次log级别的Entry回收操作,所以慢了
    get操作:ftl直接根据index进行获取,而tl需要先根据tl的hashcode计算数组下标,然后再根据线性探测法进行get操作,如果不能根据直接索引索引获取
    到value的话,并且在向后循环遍历的过程中发现了无效的Entry,则会进行无效的Entry的清理和整理工作.
    remove操作:ftl直接根据index从数组中删除当前的ftl的value,然后从Set集合中删除当前的ftl,之后还可以进行删除回调操作(功能增强);
    而tl需要先根据tl的hashCode计算数组下标,然后再根据线性探测法进行remove操作,最后还需要进行无效的Entry的整理和清理工作;


```java
    public class Demo{
        ExecutorService es;
        ThreadLocal tl;
        Object obj;
        es.execute(()->{
            // ThreadLocal增加变量
            tl.set(obj);
            try{
                
            }finally{
                tl.remove();
            }
        });
    }    
```


7.设计秒杀系统要考虑哪些点? 数据预热,CDN缓存,超卖问题,流量削峰

    数据预热
    缓存
    解决超卖
    流量削峰
    熔断限流
    弹性扩容

8.从性能角度上如何保证秒杀系统稳定?预热,削峰.减少数据库的访问,缓存

9.A B系统转账如何保证分布式数据一致性?

10.你有什么想问的?

---------------------------------------------------------

1.简单介绍下自己的近况

2.对kafka了解吗?RocketMq事务性消息怎么实现的?

    ![image_18](../image_18.png)
    消息队列中的"事务",主要解决的是消息生产者和消息消费者的数据一致性问题
    1.发送Half消息
    2.Half消息发送成功
    3.执行本地事务
    4.提交或回滚事务
    5.网络异常，Broker没有收到commit or rollback，回查本地事务状态
    6.检查本地事务状态
    7.根据本地事务状态执行commit or rollback
    8.根据 4 或 7 投递消息到MQ订阅方，或者取消不投递

3.假设事务提交的消息丢了,没有发到broker上面,会怎么处理?

    我们可以消息队列的有序性来验证是否有消息丢失.原理非常简单,在Producer端,我们给每个发出的消息附加一个连续递增的序号,  
    然后在Consumer端来检查这个序号的连续性.
    一条消息从生产到消费完成这个过程,可以划分为三个阶段
    在生产阶段:你需要捕获消息发送的错误,并重发消息
    [
        在生產阶段,消息队列通过最常用的请求确认机制,来保证消息的可靠传递:当你的代码调用发送消息方法时,消息队列的客户端
        会把消息发送Broker,Broker收到消息后,会给客户端返回一个确认响应,表明消息已经收到了.客户端收到响应后,完成了一次
        正常消息的发送.
        只要Producer收到了Broker的确认响应,就可以保证消息在生产阶段不会丢失.有些消息队列在长时间没收到发送确认响应后,
        会自动重试,如果重试再失败,就会议返回值或者抛出异常的方式告知用户
        你在编写发送消息代码时,需要注意,正确处理返回值或者捕获异常,就可以保证这个阶段的消息不会丢失.
        以kafka为例,看下如何可靠的发送消息

        try {
            RecordMetadata metadata = producer.send(record).get();
            System.out.println("消息发送成功。");
        } catch (Throwable e) {
            System.out.println("消息发送失败！");
            System.out.println(e);
        }
    
        异步发送时,则需要在回调方法里进行检查    
        producer.send(record, (metadata, exception) -> {
            if (metadata != null) {
                System.out.println("消息发送成功。");
            } else {
                System.out.println("消息发送失败！");
                System.out.println(exception);
            }
        });    
    ]

    在存储阶段:你可以通过配置刷盘和复制相关的参数,让消息写入到多个副本的磁盘上,来确保消息不会因为某个broker宕机,或者磁盘
    损坏而丢失.
    [
        在存储阶段正常情况下,只要broker在正常运行,就不会出现消息丢失的问题,但是如果Broker出现了故障,比如进程死掉了或者服务器
    宕机,还是可能会丢失消息的
    如果对消息的可靠性要求非常高,可以通过配置Broker参数来避免因为宕机丢失消息
       对于单个节点的Broker,需要配置Broker参数,在收到消息后,将消息写入磁盘后再给Producer返回确认机制,这样即使发生宕机,由于
    消息已经被写入磁盘,就不会丢失消息,恢复后还可以继续消费.在RocketMQ中,需要将双排方式FlushDiskType配置为SYNC_Flush同步刷盘
       如果是Broker是由多个节点组成的集群,需要将Broker集群配置成:至少将消息发送到2个以上的节点,再给客户端恢复发送确认响应.
    这样当某个Broker宕机时,其他的Broker可以替代宕机的Broker,也不会发生消息丢失            
    ]
      
    在消费阶段:你需要在处理完全部消费业务逻辑之后,再发送消费确认
    [
        消费阶段采用和生产阶段类似的确认机制来保证消息的可靠性,客户端从Broker拉取消息后,执行用户的消费业务逻辑,成功后,才会给Broker发送消费确认响应.
        如果Broker没有收到消费确认响应,下次拉消息的时候还会返回同一条消息,确保消息不会在网络传输过程中丢失,也不会因为客户端在执行消费逻辑中出错导致丢失.
        注意:不要在收到消息后就立即发送消费确认,而是应该在执行完成所有消费业务逻辑之后,再发送消费确认    
    ]

4.分布式事务一致性如何保证

        在单个数据库的情况下,数据事务操作具有ACID四个特性,但是如果在一个事务中操作多个数据库,则无法使用数据库事务
    来保证一致性.也就是说,当两个数据库操作数据时,可能存在一个数据库操作成功,而另一个数据库操作失败的情况,我们无法通过  
    单个数据库事务来回滚两个数据操作.  
        而分布式事务就是为了解决在同一个事务下,不同节点的数据库操作数据不一致的问题.在一个事务操作请求多个服务或者多个数据库  
    节点时,要么所有请求成功,要么所有请求都失败回滚回去.  
        通常分布式事务的实现有多种方式,例如XA协议实现的二阶段提交2PC 三阶段提交3PC,以及TCC补偿性事务

    什么是XA协议?XA协议是由X/Open组织提出的一个分布式事务处理规范,目前MySql中只有InnoDB存储引擎支持XA协议
    **1.XA规范**
    在XA规范之前,存在一个DTP模型,该模型规范了分布式事务的模型设计.
    DTP规范中主要包含了AP RM TM三个部分,其中AP是应用程序,是事务发起和结束的地方;RM是资源管理器,主要负责管理每个数据库的
    连接数据源;TM是事务管理器,负责事务的全局管理,包括事务的生命周期管理和资源的分配协调等 
    ![image_13](../image_13.png)
    XA则规范了TM与RM之间的通信接口,在TM与多个RM之间形成一个双向通信桥梁,从而在多个数据库资源下保证ACID特性;
    (JTA是基于XA规范实现的一套java事务编程接口,是一种2pc事务)
    
    **2.二阶段提交和三阶段提交**
        XA规范实现的分布式事务属于二阶提交事务,就是通过两个阶段来实现事务的提交.
    在第一阶段,应用程序向事务管理器(TM)发起事务请求,而事务管理器则会分别向参与的各个资源管理器(RM)发送事务预处理请求(prepare)
        ,此时这些资源管理器会打开本地数据库事务,然后开始执行数据库事务,但是执行完成后并不会立即提交事务,而是向事务管理器返回就绪(Ready)  
    或者未就绪(Not Ready)状态,如果各个参与节点都返回状态,就会进入第二阶段
    ![image_14](../image_14.png)
        到了第二阶段,如果资源管理器返回的都是就绪状态,事务管理器则会向各个资源管理器发送提交(Commit)通知,资源管理器则会完成本地数据库的
    事务提交,最终返回提交结果给事务管理器
     ![image_15](../image_15.png)  
         在第二阶段中,如果任意资源管理器返回了未就绪状态,此时事务管理器会向所有资源管理器发送事务回滚(Rollback)通知,此时各个资源管理器就会
    回滚本地数据事务,释放资源,并返回结果通知;  
    ![image_16](../image_16.png)

    **2PC事务存在的缺陷**
        第一,在整个流程中,我们会发现各个资源管理器节点存在阻塞,只有当所有的节点都准备完成之后,事务管理器才会发出进行全局事务提交的通知,
    这个过程如果很长,则会有很多节点长时间占用资源,从而影响整个节点的性能.
        (一旦资源管理器挂了,就会出现一致阻塞等待的情况,类似问题,我们可以通过设置事务超时时间来解决)
        第二,仍然存在数据不一致的可能性,例如,在最后通知提交全局事务时,由于网络故障,部分节点有可能收不到通知,由于这部分节点没有提交事务,就
    会导致数据不一致的情况出现.  
        而3PC事务的出现就是为了减少此类问题的发生.
        3PC把2PC的准备阶段分为了准备阶段和预处理阶段,在第一阶段只是询问各个资源节点是否可以执行事务,而在第二阶段,所有的节点反馈可以执行事务,
    才开始执行事务操作,最后在第三阶段执行提交或回滚操作.并且在事务管理器和资源管理器中都引入超时机制,如果在第三阶段,资源节点一直无法收到  
    来自资源管理器的提交或回滚请求,它就会在超时之后,继续提交事务
        所以3PC可以通过超时机制,避免管理器挂掉所造成的长时间阻塞问题,但是其实这样还是无法解决在最后提交全局事务时,由于网络故障无法通知
    到一些节点的问题,特别是回滚通知,这样会导致事务等待超时从而默认提交.

    3.事务补偿机制(TCC)    

5.2pc 3pc tcc

6.TCC对异常流式如何操作的?

7.为什么要看源码?

8.最终一致性如何实现的?

9.有没有遇到过死锁?

10.A往B转钱,B往A转钱,同时转会死锁吗?如何解决死锁?

10.设计一个全局唯一流水号?

12.设计幂等方案防止重复提交

13.大数相加

14.工厂方法模式一般如何实现?

15.单例模式

16.其他的设计模式

17.再答一次秒杀系统

18.写金融类的系统有什么需要关注的地方

19.非功能性的设计关注那些?日志规范,代码规范

20.你有什么想问的

-----------------------------------------------------

1.如何提前发现你的数据有问题,而不是等到用户反馈才知道?

2.如何防止超卖?

3.为什么要用Redis?为什么没有用db?

4.有没有QPS?

5.如何部署?

6.rocketmq发生过丢消息的情况吗?为什么会丢失?

7.项目过程中哪个点比较难?

8.项目中为什么要用ThreadLocal去做租户的隔离?

9.项目有什么缺点?

10.100亿行数据,每个数字32位,取最小的数字

11.有没有碰到特别难的事情,如何解决的?

12.业界中间件有什么了解吗?将一个你深度理解原理的

13.高并发的问题有遇到过吗?

14.有遇到过很大的流量吗?

15.描述产生一次FullGC的整个过程

16.平时通过什么来提升自己?

17.你有什么问题?你觉得我的短板在于?

------------------------------------------------------------------------

1.简单介绍下自己和项目
自我介绍:面试官你好,我叫李昭文,本科毕业于安徽巢湖学院,现居苏州吴江,从Boss招聘上看到公司招聘的这个java职位,我觉得自己比较适合公司的这个岗位,对自己的发展也有帮助,所以来争取下这份工作.
本人从事java开发有将近6年的开发经验,从事过不同业务场景开发,例如互联网金融 微信公众号 共享仓库存储等场景,可以适应不同场景的开发工作;  
期间解决了许多疑难问题,(本人总结了解决问题的三个步骤:首先,许多bug在于理解需求不清,因此写代码时有疑问的地方要多和产品 开发leader沟通好,其次代码层次要简洁明了,逻辑清楚,多测试,出了bug,自己能做到心中有数;再次要和测试人员加强沟通)
本人的优势在于痴迷技术,学习能力强,为人谦和,缺点在于非计算机专业,有时考虑问题不够全面.
谢谢面试官

项目介绍:目前本人在开发的项目,是一款既有web端,也有安卓端,还有小程序的项目,叫做任意仓,任意仓就是负责电商卖家的仓储租赁+配送的业务.
本人负责云仓出入库单 物流单模块中接口的定义,利用设计模式优化代码(观察者模式),确保接口访问的幂等性,优化出入库单请求响应参数



2.你觉得项目里最大的挑战是什么?项目的设计和推动

3.为什么选择rocketmq?

4.对rocketMQ的了解?
基本原理 发布订阅 服务注册 消息丢失

5.消息如何保证顺序消费?

6.rocketmq事务消息

7.rocketmq是强一致性还是还是弱一致性?

8.消息重复如何解决?可以在中间件层解决吗?MQ体系一些了解吗?业务幂等等

9.ThreadLocal是怎么样概念?如何实现线程隔离的?基于这个原理有没有更加优化的方式

10.线程池用ThreadLocal有什么问题?有什么思路来让业务不去关注ThreadLocal的set ThreadLocal在线程复用的时候
值可能不是最新的,需要每次都set

11.你说你用过dubbo,那看过netty源码吗?

12.Netty中FastThreadLocal对ThreadLocal的优化

13.讲讲dubbo的基本原理

14.JVM调优?

15.频繁YGC如何排查

16.为什么会发生YGC

17.如何知道哪些对象需要被回收

18.GCRoot有哪些

19.堆和栈的区别?

20.什么时候会压栈

21.程序都是线程在执行,线程和栈和堆的关系

22.HashMap如何实现?为什么会变红黑树?如何扩容?为什么是两倍?什么时候用到位运算?

23.你有什么想问的?



