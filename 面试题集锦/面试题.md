1.TreeSet和HashSet的区别
ans:两者主要在实现方式 数据是否有序,以及是否可以放入null值等三方面存在区别
一.实现方式
a.HashSet底层采用HashMap,也就是hash表实现
b.TreeSet底层采用TreeMap,也就是红黑树实现
二.数据是否有序
HashSet中的数据是无序的
TreeSet中数据可以根据自然排序Comparable和比较排序Comparator进行排序
三.是否可以放入null值
HashSet可以放入null,但是只能放入null,(key==null,key键的hash值将为0,HashMap使用第0个桶存放键为null的键值对)  
而TreeSet不允许放入null(无法进行比较)

2.HashMap如何解决冲突,扩容机制
HashMap是基于哈希表的数据结构实现的
常用的数据结构:数组 链表 哈希表 树
哈希表将键的hash值映射到内存地址,也就是说HashMap是根据键的Hash值来决定对应值的存储位置.通过这种索引方式,HashMap获取数据的速度会非常快.
两个对象的存储地址冲突,这种现象被称为哈希冲突,哈希表是怎么解决的呢?开放地址法 再哈希函数法和链地址法

**开放地址法**:当发生哈希冲突时,如果哈希表未被装满,说明在哈希表中必然还有空位置,那么可以把key存放到冲突位置后面的空位置上去.这种方法存在着很多
缺点,例如查找 扩容.所以不建议作为解决哈希冲突的首选

**再哈希法**:在同一词产生地址冲突时再计算另一个哈希函数地址,直到冲突不再发生,这种方法不易产生"聚集",但却增加了计算时间,如果不考虑增加元素的时间,  
且对查询元素的要求极高,就可以考虑使用这种算法设计.

**链地址法**:这种方法时采用了数组(哈希表)+链表的数据结构,当发生哈希冲突时,就用一个链表结构存储相同hash值的数据

**HashMap的重要属性**:HashMap是由一个Node数组构成,每个Node包含了一个key-value键值对.
```java
public class HashMap{
    transient Node<K,V>[] table;
    int threshold;// 边界值
    final float loadFactor;// 加载因子
    
    static class Node<K,V> implements Map.Entry<K,V>{
        final int hash;
        final K key;
        V value;
        Node<K,V> next;
         Node(int hash, K key, V value, Node<K,V> next) { 
             this.hash = hash;          
             this.key = key;           
             this.value = value;        
             this.next = next;      
         }
    }
}
```

**HashMap添加元素优化**:
```java
public class HashMap{
 public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
  
 static final int hash(Object key) {
        int h;
        // (h = key.hashCode()) ^ (h >>> 16)尽量打乱hashcode真正参与运算的低16位
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    } 
  void put(){
  if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        //通过putVal方法中的(n - 1) & hash决定该Node的存储位置
        // (n - 1) & hash,n为2的n次方,这样恰好可以保证计算得到的索引值总是位于table数组的索引之内
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
  }  
}
```
put方法流程
1.开始put
2.判断table为null或者tab的长度为0时,通过resize()方法得到初始化table
3.通过(n - 1) & hash计算出的值作为tab的下标i,并判断该下标i的节点是否为null
4.如果3为true,则new第一个Node节点,调用newNode方法返回新节点赋值给tab[i]
5.如果3为false,则分为三种情况处理
a.如果存在相等key值的节点,HashMap中判断是否存在key和插入的key相等,如果相等,则将存在key值的Node覆盖
b.判断新增节点是否为红黑树节点,如果是则新增红黑树节点
c.轮询新增节点所在的链表长度,判断长度是否超过TREEIFY_THRESHOLD
c1.如果超过,则将链表转为红黑树,否则在链表尾部新增Node节点
```java
public class HashMap{
    
 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
        //1、判断当table为null或者tab的长度为0时，即table尚未初始化，此时通过resize()方法得到初始化的table
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) & hash]) == null)
        //1.1、此处通过（n - 1） & hash 计算出的值作为tab的下标i，并另p表示tab[i]，也就是该链表第一个节点的位置。并判断p是否为null
            tab[i] = newNode(hash, key, value, null);
        //1.1.1、当p为null时，表明tab[i]上没有任何元素，那么接下来就new第一个Node节点，调用newNode方法返回新节点赋值给tab[i]
        else {
        //2.1下面进入p不为null的情况，有三种情况：p为链表节点；p为红黑树节点；p是链表节点但长度为临界长度TREEIFY_THRESHOLD，再插入任何元素就要变成红黑树了。
            Node<K,V> e; K k;
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
        //2.1.1HashMap中判断key相同的条件是key的hash相同，并且符合equals方法。这里判断了p.key是否和插入的key相等，如果相等，则将p的引用赋给e
                e = p;
            else if (p instanceof TreeNode)
        //2.1.2现在开始了第一种情况，p是红黑树节点，那么肯定插入后仍然是红黑树节点，所以我们直接强制转型p后调用TreeNode.putTreeVal方法，返回的引用赋给e
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
        //2.1.3接下里就是p为链表节点的情形，也就是上述说的另外两类情况：插入后还是链表/插入后转红黑树。另外，上行转型代码也说明了TreeNode是Node的一个子类
                for (int binCount = 0; ; ++binCount) {
        //我们需要一个计数器来计算当前链表的元素个数，并遍历链表，binCount就是这个计数器

                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) 
        // 插入成功后，要判断是否需要转换为红黑树，因为插入后链表长度加1，而binCount并不包含新节点，所以判断时要将临界阈值减1
                            treeifyBin(tab, hash);
        //当新长度满足转换条件时，调用treeifyBin方法，将该链表转换为红黑树
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
}
```

**HashMap获取元素优化**:当HashMap中只存在数组,而数组中没有Node链表时,是HashMap查询性能最好的时候.一旦
发生大量的哈希冲突,就会产生Node链表,这个时候每次查询元素都可能遍历Node链表,从而降低查询数据的性能.特别是在链表
长度过长的情况下,性能将明显降低,红黑树的使用很好的解决了这个问题,使得查询的平均复杂度降低到了O(log(n)),链表越长,
使用红黑树替换后的查询效率提升就越明显.

**HashMap**扩容优化:在jdk1.8中,HashMap对扩容操作做了优化.由于扩容数组的长度是2倍关系,所以对于假设初始tableSize=4
要扩容到8来说,就是0100到1000的变化,在扩容中只用判断原来的hash值和左移动的一位(newTable的值)按位与操作是0或1就行,
0的话索引不便,1的话索引变成原索引加上扩容前数组.
之所以呢能通过这种"与运算"来重新分配索引,是因为hash值本来就是随机的,而hash按位与上newTable得到的0(扩容前的索引位置)和1(扩容前的索引位置加上扩容前数组长度的数值索引处)
就是随机的,所以扩容的过程就能把之前哈希冲突的元素再随机分布到不同的索引中去

**链地址法**:这种方法的基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。


3.ConcurrentHashMap如何做到高并发的?
>为什么需要CHM?
> 一是因为HashTable本身比较低效,因为它的实现基本就是将put get size等各种方法加上synchronized.简单来说,这就导致了
> 所有并发操作都要竞争同一把锁,一个线程在进行同步操作时,其他线程只能等待,大大降低了并发操作的效率

>二是HashMap不支持线程的同步，即任一时刻可以有多个线程同时写HashMap;可能会导致数据的不一致

>三能不能利用Collections提供的同步包装器来解决问题?同步包装器只是利用输入Map够早了另一个同步版本,所有操作虽然不再声明称为
> synchronized方法,但是还是利用了"this"作为互斥的mutex,没有真正意义上的改进
```java

private static class SynchronizedMap<K,V>
    implements Map<K,V>, Serializable {
    private final Map<K,V> m;     // Backing Map
    final Object      mutex;        // Object on which to synchronize
    // …
    public int size() {
        synchronized (mutex) {return m.size();}
    }
 // 
}
```
所以，Hashtable 或者同步包装版本，都只是适合在非高度并发的场景下
***分析CHM***
1.7
put加锁,
通过分段加锁segment,一个hashmap里有若干个segment,每个segment里有若干个桶,
桶里存放k-V形式的链表,put数据时通过key哈希得到该元素要添加的segment,然后对segment
进行加锁,然后在哈希,计算得到给元素要添加到的桶,然后遍历桶中的链表,替换或新增节点到桶中

size:分段计算两次

1.8
put CAS加锁
1.8中不依赖与segment加锁,segment数量与桶数量一致
首先判断容器是否为空,为空则进行初始化,
initTable()利用volatile的sizeCtl作为互斥手段,如果发现竞争性的初始化,就暂停
在哪里,等待条件恢复;
否则初始化时利用CAS设置排他标志sizeCtl;
否则重试初始化;
如果容器不为空但节点bin是空的,则利用CAS去进行无锁操作线程
对key hash计算得到该key存放的的桶位置,判断该桶是否为空,为空则利用CAS设置新节点;
否则使用synchronized加锁,遍历桶中数据,替换桶中数据,替换或新增加点到桶中;
最后判断是否需要转为红黑树,转换之前判断是否需要扩容

size:利用LongAdd累计计算

put方法流程
1.首先判断容器是否为空,为空则进行初始化initTable()
2.如果容器不为空,但是根据tabAt(table,(n-1)&hash))==null,为true,则利用CAS进行无锁操作,对key进行hash计算
得到key存放的桶位置,判断该桶是否为空,为空则利用CAS设置新节点
3.根据tabAt(table,(n-1)&hash))==null,为false,(fh = f.hash) == MOVED为true,则当前线程帮助搬移数据
4.如果以上都不是,则使用synchronized对该节点加锁,遍历通中数据,替换桶中数据,新增加节点到数据

```java
public class ConcurrentHashMap{
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    break;                   // no lock when adding to empty bin
            }
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key,
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }
    private final Node<K,V>[] initTable() {
        Node<K,V>[] tab; int sc;
        while ((tab = table) == null || tab.length == 0) {
            if ((sc = sizeCtl) < 0)
                Thread.yield(); // lost initialization race; just spin
            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    if ((tab = table) == null || tab.length == 0) {
                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                        @SuppressWarnings("unchecked")
                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                        table = tab = nt;
                        sc = n - (n >>> 2);
                    }
                } finally {
                    sizeCtl = sc;
                }
                break;
            }
        }
        return tab;
    }
}
```

initTable流程
利用volatile的sizeCtl作为互斥手段,如果发现竞争性的初始化,就暂停在哪里,等待条件恢复;
否则初始化时利用CAS设置排他标志sizeCtl;
否则重试初始化;
白话解释下:从源码中可以看出table的初始化在一个cas方法中进行,当table为null或者长度为0时,进入之后判断
sizeCtl的值,如果sizeCtl<0则线程让步,由于初始化状态sizeCtl是等于0的,说明前面已经有线程进入了else if这部分,
将sizeCtl的值置为-1,表示正在初始化


4.线程池平常怎么用
**线程池原理**:在线程池内部,维护了一个阻塞队列workQueue和一组工作线程,工作线程的个数由构造函数中的poolsize来指定.
用户通过调用execut()方法来提交Runnable任务,execute()方法的内部实现仅仅是将任务加入到workQueue中.线程池内部维护的
工作线程会消费WorkQueue中的任务并执行任务.
```java

//简化的线程池，仅用来说明工作原理
class MyThreadPool{
  //利用阻塞队列实现生产者-消费者模式
  BlockingQueue<Runnable> workQueue;
  //保存内部工作线程
  List<WorkerThread> threads = new ArrayList<>();
  // 构造方法
  MyThreadPool(int poolSize, BlockingQueue<Runnable> workQueue){
    this.workQueue = workQueue;
    // 创建工作线程
    for(int idx=0; idx<poolSize; idx++){
      WorkerThread work = new WorkerThread();
      work.start();
      threads.add(work);
    }
  }
  // 提交任务
  void execute(Runnable command){
    workQueue.put(command);
  }
  // 工作线程负责消费任务，并执行任务
  class WorkerThread extends Thread{
    public void run() {
      //循环取任务并执行
      while(true){ 
        Runnable task = workQueue.take();
        task.run();
      } 
    }
  }

/** 下面是使用示例 **/
public static void main(String[] args) {
    // 创建有界阻塞队列
    BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue<>(2);
    // 创建线程池  
    MyThreadPool pool = new MyThreadPool(10, workQueue);
    // 提交任务  
    pool.execute(()->{System.out.println("hello"); });
  }
}
```
**线程应用的场景**:普通的场景,使用工厂类Executors创建就可以了.常见的有fix Single cache三种,
更多时候,为了更精细的控制,会直接对ThreadPoolExecutor类进行定制,我尤其关系其中的阻塞队列和饱和策略
**线程池拒绝策略**:
**线程池参数介绍**:把线程池类比为一个项目组,而线程就是项目组中的成员
```java
public class ThreadPoolExecutor{
    ThreadPoolExecutor(
      int corePoolSize,// 表示线程池保有的最小线程数.有些项目很闲,但是也不能把人都撤了,至少要保留corePoolSize个人坚守阵地
      int maximumPoolSize,// 表示线程池创建的最大线程数.当项目很忙时,就需要家加人,但是也不能无限加,最多加到maximumPoolSize个人
      long keepAliveTime,// 项目根据忙闲开增减人员,在编程世界里,如何定义忙和闲呢?一个线程如果在一段时间内,都没有执行任务,说明很闲,
      TimeUnit unit,// keepAliveTime&unit就是用来定义这个"一段时间"的参数,也就是说一个线程空闲了keepAliveTime&unit了这么久,而且线程池的线程数大于corePoolSize,na那么这个空闲的线程就要被回收了
      BlockingQueue<Runnable> workQueue,// 工作队列
      ThreadFactory threadFactory,//通过这个参数可以自定义如何创建线程,例如可以给线程指定一个有意义的名字
      RejectedExecutionHandler handler); //通过这个参数可以自定义任务的拒绝策略.如果线程池中所有的线程都在忙碌,并且工作队列也满了,前提是工作队列是有界队列,name
      // 此时提交任务,线程池就会拒绝接收
  }
```
CallerRunsPolicy:提交任务的线程自己去执行该任务
AbortPolicy:默认的拒绝策略,会抛出异常
DiscardPolicy:直接丢弃任务,没有异常
DiscardOldestPolicy:丢弃最老的任务

```java
public class Executors{
    public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
     public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>(),
                                      threadFactory);
    }
    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }
}
```
5.多个线程等到某一节点然后统一放行有几种实现方式?
CountDownLatch主要用来解决一个线程等待多个线程的场景,可以类比旅游团团长要等待所有的游客到齐才能去下一个景点,
主线程阻塞在await方法,每个线程调用countDown()
CyclicBarrier 是一组线程之间互相等待,更像是几个驴友之间不离不弃,每个线程阻塞在await上,达到一定阈值集体放行
Future实现线程之间的等待
6.数据库索引结构?
哈希表 有序数组 搜索树
哈希表这种结构适用于等值查询的场景(处理冲突的方式是链表)
有序数组在等值查询和范围查询场景中的性能都很非常优秀,优点:查询效率高,缺点:插入一条记录成本高
有序数组索引只适用静态存储引擎
二叉搜索树

7.select * from t where a=? and b>? order by c limit 0,100如何加索引

8.什么是聚簇索引和非聚簇索引?
主键索引的叶子节点存的是整行数据,在InnoDB中,主键索引被称为聚簇索引
非主键索引的叶子节点内容是主键的值,在InnoDB中,非主键索引也被称为二级索引,也被称为非聚簇索引
基于主键索引和普通索引的查询有什么区别?
如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；  
如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。  
这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

9.了解CAP吗?redis里的CAP是怎样的
>a.什么是CAP?
>结合电商的例子,理解CAP的含义?
>假设某电商在北京 杭州 上海三个城市建立了仓库,同时建立了对应的服务器A B C,用于存储商品信息.比如,某电吹风在北京仓库有20个,在杭州仓库
> 有10个,在上海仓库有30个.那么,CAP这三个字母在这个例子中分别代表什么呢?
>C 代表Consistency,一致性,是指所有节点在同一时刻的数据时相同的,即更新操作执行结束并响应用户完成后,所有节点存储的数据会保持相同.
> 在电商系统中,A B C 中存储的该电吹风的数量应该是20+10+30=60.假设,现在有一个北京用户买走一个电吹风,服务器A会更新数据为60-1=59,
> 与此同时要求B和C也更新为59,以保证在同一时刻,无论访问A B C 中的哪个服务器,得到的数据均是59;
> A代表Availability,可用性,是指系统提供的服务一直处于可用状态,对于用户的请求可即时响应
> 在电商系统中,用户在任一时刻向A B C中的任一服务器发出请求时,均可得到即时响应,比如查询商品信息等.
> P代表Partition Tolerance,分区容错性,是指在分布式系统遇到网路分区的情况下,仍然可以响应用户的请求.网络分区是指因为网络故障不连通,不同节点分布在不同的子网络
> 中,各个子网络内网络正常.
>在电商系统中,假设C和A B的网络都不通了,A和B是相通的.也就是说,形成了两个分区{A,B}和{C},在这种情况下,系统仍能响应用户请求.
>一致性 可用性 分区容错性是分布式系统的三个特征,那么我们平时所说的CAP理论又是什么呢?
> CAP理论指的就是在分布式系统中C A P这三个特征不能同时满足,只能满足其中两个
>
>
>
>
>
>
>
>
>
>
>
>
>
>
10.如何理解幂等?项目中接口的幂等是如何做的?

11.算法题:两个有序的list,求交集

-------------------------------------------------

1.解释下乐观锁和悲观锁

2.jvm判断对象是否回收?

3.反射能获得类里面方法的名称吗?参数名称呢?参数类型呢?

4.动态代理的实现方式?cglib和jdk的代理有什么区别?

5.分布式锁游戏主流实现方式?redis 和 zk锁有什么区别?

6.ThreadLocal作用是什么?说下用法

7.设计秒杀系统要考虑哪些点? 数据预热,CDN缓存,超卖问题,流量削峰

8.从性能角度上如何保证秒杀系统稳定?预热,削峰.减少数据库的访问,缓存

9.A B系统转账如何保证分布式数据一致性?

10.你有什么想问的?

---------------------------------------------------------

1.简单介绍下自己的近况

2.对kafka了解吗?RocketMq事务性消息怎么实现的?

3.假设事务提交的消息丢了,没有发到broker上面,会怎么处理?

4.分布式事务一致性如何保证

5.2pc 3pc tcc

6.TCC对异常流式如何操作的?

7.为什么要看源码?

8.最终一致性如何实现的?

9.有没有遇到过死锁?

10.A往B转钱,B往A转钱,同时转会死锁吗?如何解决死锁?

10.设计一个全局唯一流水号?

12.设计幂等方案防止重复提交

13.大数相加

14.工厂方法模式一般如何实现?

15.单例模式

16.其他的设计模式

17.再答一次秒杀系统

18.写金融类的系统有什么需要关注的地方

19.非功能性的设计关注那些?日志规范,代码规范

20.你有什么想问的

-----------------------------------------------------

1.如何提前发现你的数据有问题,而不是等到用户反馈才知道?

2.如何防止超卖?

3.为什么要用Redis?为什么没有用db?

4.有没有QPS?

5.如何部署?

6.rocketmq发生过丢消息的情况吗?为什么会丢失?

7.项目过程中哪个点比较难?

8.项目中为什么要用ThreadLocal去做租户的隔离?

9.项目有什么缺点?

10.100亿行数据,每个数字32位,取最小的数字

11.有没有碰到特别难的事情,如何解决的?

12.业界中间件有什么了解吗?将一个你深度理解原理的

13.高并发的问题有遇到过吗?

14.有遇到过很大的流量吗?

15.描述产生一次FullGC的整个过程

16.平时通过什么来提升自己?

17.你有什么问题?你觉得我的短板在于?

------------------------------------------------------------------------

1.简单介绍下自己和项目

2.你觉得项目里最大的挑战是什么?项目的设计和推动

3.为什么选择rocketmq?

4.对rocketMQ的了解?
基本原理 发布订阅 服务注册 消息丢失

5.消息如何保证顺序消费?

6.rocketmq事务消息

7.rocketmq是强一致性还是还是弱一致性?

8.消息重复如何解决?可以在中间件层解决吗?MQ体系一些了解吗?业务幂等等

9.ThreadLocal是怎么样概念?如何实现线程隔离的?基于这个原理有没有更加优化的方式

10.线程池用ThreadLocal有什么问题?有什么思路来让业务不去关注ThreadLocal的set ThreadLocal在线程复用的时候
值可能不是最新的,需要每次都set

11.你说你用过dubbo,那看过netty源码吗?

12.Netty中FastThreadLocal对ThreadLocal的优化

13.讲讲dubbo的基本原理

14.JVM调优?

15.频繁YGC如何排查

16.为什么会发生YGC

17.如何知道哪些对象需要被回收

18.GCRoot有哪些

19.堆和栈的区别?

20.什么时候会压栈

21.程序都是线程在执行,线程和栈和堆的关系

22.HashMap如何实现?为什么会变红黑树?如何扩容?为什么是两倍?什么时候用到位运算?

23.你有什么想问的?



