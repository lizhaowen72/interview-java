1.解释下乐观锁和悲观锁

    悲观锁总是假设情况最坏,每次操作数据都认为别人会来修改,就加锁来保证安全.后面的访问者只能等待.
    数据库中的行锁 表锁,java中的同步关键字等,都属于悲观锁
    乐观锁正好相反,总是假设最好的情况,不用对数据加锁,但是多了一次额外的判断.比如并发包中大量的CAS操作 判断新旧版本号机制等
    ***悲观锁是老婆,由你独占;乐观锁是炮友,按预约规划***
2.jvm判断对象是否回收?

    一般一个对象不再被引用,就代表该对象可以被回收?目前根据可达性分析算法判断该对象是否可以被回收.
    可达性分析算法:GCRoots是该算法的基础,GCRoots是所有对象的根对象,在jvm加载时,会创建一些普通对象引用正常对象.
    这些对象作为正常对象的起始点,在垃圾回收时,会从这些GCRoots开始向下搜索,当一个对象到GCRoots没有任何引用链相连时,
    就证明此对象是不可用的.
    GCRoots有哪些?
    a.虚拟机栈中引用的对象
    b.本地方法栈中jni引用的对象
    c.方法区中的静态变量和常量引用的对象
    d.活跃线程引用的对象

3.反射能获得类里面方法的名称吗?参数名称呢?参数类型呢?

    都可以.jdk8以后通过Parameter类获取参数名称.但有前提,需要加编译开关
    javac -parameters
    默认是关闭的

4.动态代理的实现方式?cglib和jdk的代理有什么区别?

    1.通过实现InvocationHandler接口创建自己的调用处理器
    2.通过为Proxy类指定ClassLoader对象和一组interface以及自己的调用处理器,来创建动态代理类
    3.通过反射机制获得动态代理类的构造函数,其唯一参数类型是调用处理器接口类型
    4.通过构造函数创建动态代理类实例,构造时调用处理器对象作为参数传入
    
    **jdkProxy的优势**:
        最小化依赖关系,减少依赖意味着简化开发和维护,jdk本身的支持,可能比cglib更加可靠
        平滑进行jdk版本升级,而字节码类库通常需要进行更新以保证在新版java上能够使用
        代码实现更简单
    **CGLib的优势**:  
        有的时候调用目标不便实现额外接口,从某种角度看,限定调用者实现接口是有些侵入性的实践,类似cglib动态代理就没有这种限制  
        只操作我们关心的类,而不必为其他相关类增加工作量  
        高性能  
    **总结**:
        静态代理:事先写好代理类,可以手工编写,也可以用工具生成.缺点是每个业务类都要对应一个代理类,非常不灵活  
        动态代理:运行时自动生成代理对象.缺点是生成代理对象和调用代理方法都要额外花费时间  
            jdk动态代理:基于java反射机制实现,必须要实现了接口的业务类才能用这种办法生成代理对象,新版本也开始结合ASM机制  
            cglib动态代理:基于ASM机制实现,通过生成业务类的子类作为代理类  
            ASM机制:ASM是被设计用于运行时的，离线的类生成和转换，作用于已编译好的Java class，并且被设计的尽可能的小巧快速，  
            其目的是生成、转换和分析以字节数组表示的已编译 Java 类(它们在磁盘中的存储 和在 Java 虚拟机中的加载都采用这种字节数组形式)。  
            为此，ASM 提供了一些工具，使用高于字节级别的概念来读写和转换这种字节数组，这些概念包括数值常数、字符串、Java 标识符、Java  
            类型、Java 类结构元素，等等。注意，ASM 库的范围严格限制于类的读、写、转换和分析。具体来说，类的加载过程就超出了它的范围之外

5.分布式锁有哪些主流实现方式?Redis和zk锁有什么区别?

    大体分为两类
    乐观锁:
        基于版本号机制和CAS实现,与存放版本号的存储无关
    悲观锁:  
        1.基于数据库记录,进入时写数据,退出时删除记录  
        2.数据库行锁,它是一把排他锁  
        3.基于Redis的setNx函数  
        4.基于zookeeper  
        区别:redis获取锁是轮询机制.锁释放后会有多个调用者争抢,某些任务可能会饿死  
        zk是监听机制,有变动会接到通知.除了非公平锁,也可以实现公平锁

6.ThreadLocal作用是什么?说下用法

    ThreadLocal用来隔离数据
    ThreadLocal中存放的是与线程相关的数据,底层实际上是一个map,通过线程可以获取存储数据的相关信息
    一些需要绑定到线程的数据,比如一些线程的统计数据,就可以放在这里

    (java并发编程实战)ThreadLocal的实现里面有一个Map,叫做ThreadLocalMap,不过持有ThreadLocalMap的不是ThreadLocal,
    而是Thread. Thread这个类内部有一个私有属性threadLocals,其类型就是ThreadLocalMap,ThreadLocalMap的key就是是ThreadLocal.
    为何这样设计?
    一是ThreadLocal仅仅是一个代理工具类,内部并不持有任何与线程相关的数据,所有和线程相关的数据都存储在Thread里面,这样的设计更容易理解.
    并且从数据的亲缘性上来讲,ThreadLocalMap属于Thread也更加合理
    二是不容易产生内存泄漏,Thread持有ThreadLocalMap,ThreadLocalMap里对ThreadLocal的引用还是弱引用(WeakReference),
    所以只要Thread对象可以被回收,那么ThreadLocalMap就能被回收
    
    ThreadLocal与内存泄漏
    在线程池中使用ThreadLocal为什么可能导致内存泄漏?
    原因就出在线程池中线程的存活时间太长,往往都是和程序同生共死的,这就意味着Thread持有的ThreadLocalMap一直都不会被回收,
    再加上ThreadLocalMap中的Entry对ThreadLocal是弱引用,所以只要ThreadLocal结束了自己的生命周期是可以被回收掉的,但是Entry中的value
    却是被Entry强引用的,所以即便value的生命周期结束了,value也是无法被回收的,从而导致内存泄漏
    那在线程池中,该如何正确使用ThreadLocal呢?其实很简单,既然jvm不能做到自动释放对value的强引用,那我们手动释放就可以了.如何能做到手动释放呢?
    try{} finally{}方案,手动释放资源利器
    
    ThreadLocal的优化方式FastThreadLocal
    FastThreadLocal使用了单纯的数组来替代ThreadLocal的hash表操作,索引在高并发的情况下,FastThreadLocal更快
    set操作:FastThreadLocal直接根据index进行数组set,而 ThreadLocal 需要先根据ThreadLocal的hashcode计算数组下标,然后
    再根据线性探测法进行set操作,期间如果发生hash冲突且有无效的Entry时,还要进行entry的清理和整理操作.最后不管是否冲突,都要进行
    一次log级别的Entry回收操作,所以慢了
    get操作:ftl直接根据index进行获取,而tl需要先根据tl的hashcode计算数组下标,然后再根据线性探测法进行get操作,如果不能根据直接索引索引获取
    到value的话,并且在向后循环遍历的过程中发现了无效的Entry,则会进行无效的Entry的清理和整理工作.
    remove操作:ftl直接根据index从数组中删除当前的ftl的value,然后从Set集合中删除当前的ftl,之后还可以进行删除回调操作(功能增强);
    而tl需要先根据tl的hashCode计算数组下标,然后再根据线性探测法进行remove操作,最后还需要进行无效的Entry的整理和清理工作;


```java
    public class Demo{
        ExecutorService es;
        ThreadLocal tl;
        Object obj;
        es.execute(()->{
            // ThreadLocal增加变量
            tl.set(obj);
            try{
                
            }finally{
                tl.remove();
            }
        });
    }    
```


7.设计秒杀系统要考虑哪些点? 数据预热,CDN缓存,超卖问题,流量削峰
a.秒杀系统架构设计都有哪些关键点?

        如何才能更好的理解秒杀系统呢?我觉得作为一个程序员,首先需要从高纬度出发,从整体上个思考问题.
    在我看来,秒杀其实主要解决两个问题,一个是并发读,一个是并发写.并发读的核心优化理念是尽量减少用户到服务端来"读"数据,
    或者让他们读更少的数据;并发写的处理原则也一样,她要求我们在数据层面独立出来一个库,做特殊的处理.另外,我们还要
    针对秒杀系统做一些保护,针对意料之外的情况设计兜底方案,防止最坏的情况发生.
        而从一个架构师的角度来看,要想打造并维护一个超大流量并发读写 高性能 高可用的系统,在整个用户请求路径上从浏览器
    到服务端我们要遵循几个原则,就是要保证用户请求的数据尽量少 请求数尽量少 路径尽量短 依赖尽量少,并且不要有单点.
        其实,秒杀的整体架构可以概括为"稳" "准" "快"几个关键字.
        所谓"稳",就是整个系统架构要满足高可用,流量符合预期时肯定要稳定,就是超出预期时也同样不能掉链子,你要保证秒杀活动顺利
    完成,即秒杀商品顺利的卖出去,这个是最基本的前提.
        然后就是"准",就是秒杀10台iPhone,那就只能成交10台,多一台少一台都不行,一旦库存不对,那平台就要承担损失,所以"准"
    就是要求保证数据的一致性.
        最后再看"快",就是系统的性能要足够高,否则怎么支撑这么大的流量?不光是服务端要做极致的性能优化,而且在整个请求链路上都要
    做协同的优化,每个地方快一点,整个系统就完美了.
        所以从技术角度上看"稳" "准" "快",就对应了我们架构上的高可用 一致性和高性能的要求.
        高性能:秒杀涉及大量的并发读和并发写,因此支持高并发访问这点非常关键.将从设计数据的动静分离 热点的发现与隔离 请求的削峰与分层过滤
    服务端的极致优化这4个方面重点分析
        一致性:秒杀中商品减库存的实现方式同样关键.可想而知,有限数量的商品在同一时刻被很多倍的请求同时来减库存,减库存又分为"拍下减库存"
    "付款减库存"以及预扣等几种,在大并发更新的过程中都要保证数据的准确性,其难度可想而知.
        高可用:现实中总难免出现一些我们考虑不到的情况,所以要保证系统的高可用和正确性,我们还需要设计一个PlanB;来兜底,以便在最坏情况发生
    时仍然能够从容应对                       
b.设计秒杀系统时应该注意的5个架构原则

        秒杀系统本质上就是一个满足大并发 高性能和高可用的分布式系统.现在我们就来聊聊,如何在满足一个良好架构的分布式系统基础上,针对秒杀这种业务
    做到极致的性能改进
        架构原则4要1不要
    1.数据要尽量少
        所谓数据要尽量少,首先是指用户请求的数据能少就少.请求的数据包括上传给系统的数据和系统返回给用户的数据(通常就是网页);
    为啥“数据要尽量少”呢？因为首先这些数据在网络上传输需要时间，其次不管是请求数据还是返回数据都需要服务器做处理，而服务器在写网络时通常都要做压缩和字符编码，
    这些都非常消耗 CPU，所以减少传输的数据量可以显著减少 CPU 的使用。例如，我们可以简化秒杀页面的大小，去掉不必要的页面装修效果
         其次，“数据要尽量少”还要求系统依赖的数据能少就少，包括系统完成某些业务逻辑需要读取和保存的数据，这些数据一般是和后台服务以及数据库打交道的。
     调用其他服务会涉及数据的序列化和反序列化，而这也是 CPU 的一大杀手，同样也会增加延时。而且，数据库本身也容易成为一个瓶颈，所以和数据库打交道越少越好，数据越简单、越小则越好。
    2.请求数要尽量少
         用户请求的页面返回后，浏览器渲染这个页面还要包含其他的额外请求，比如说，这个页面依赖的 CSS/JavaScript、图片，以及 Ajax 请求等等都定义为“额外请求”，
    这些额外请求应该尽量少。因为浏览器每发出一个请求都多少会有一些消耗，例如建立连接要做三次握手，有的时候有页面依赖或者连接数限制，一些请求（例如 JavaScript）
    还需要串行加载等。另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析，可能会耗时更久。所以你要记住的是，减少请求数可以显著减少以上这些因素导致的资源消耗。 
    例如，减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件，把多个 JavaScript 文件合并成一个文件，
    在 URL 中用逗号隔开（https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js）。
    这种方式在服务端仍然是单个文件各自存放，只是服务端会有一个组件解析这个 URL，然后动态把这些文件合并起来一起返回。
    3.路径要尽量短
    所谓“路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数。通常，这些节点可以表示为一个系统或者一个新的 Socket 连接
    （比如代理服务器只是创建一个新的 Socket 连接来转发请求）。每经过一个节点，一般都会产生一个新的 Socket 连接。然而，每增加一个连接
    都会增加新的不确定性。从概率统计上来说，假如一次请求经过 5 个节点，每个节点的可用性是 99.9% 的话，那么整个请求的可用性是：99.9% 的 5 次方，
    约等于 99.5%。所以缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），
    并减少延时（可以减少网络传输耗时）。要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用
    4.依赖要尽量少
    所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖。举个例子，比如说你要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，
    还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。要减少依赖，我们可以给系统进行分级，比如 0 级系统、
    1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统，以此类推。注意，0 级系统要尽量减少对 1 级系统的强依赖，
    防止重要的系统被不重要的系统拖垮。例如支付系统是 0 级系统，而优惠券是 1 级系统的话，在极端情况下可以把优惠券给降级，防止支付系统被优惠券这个 1 级系统给拖垮。
    5.不要有单点
    系统中的单点可以说是系统架构上的一个大忌，因为单点意味着没有备份，风险不可控，我们设计分布式系统最重要的原则就是“消除单点”。那如何避免单点呢？我认为关键点是
    避免将服务的状态和机器绑定，即把服务无状态化，这样服务就可以在机器中随意移动。如何那把服务的状态和机器解耦呢？这里也有很多实现方式。
    例如把和机器相关的配置动态化，这些参数可以通过配置中心来动态推送，在服务启动时动态拉取下来，我们在这些配置中心设置一些规则来方便地改变这些映射关系。应用无状态化
    是有效避免单点的一种方式，但是像存储服务本身很难无状态化，因为数据要存储在磁盘上，本身就要和机器绑定，那么这种场景一般要通过冗余多个备份的方式来解决单点问题。
    架构是一种平衡的艺术,而最好的架构一旦脱离了它所适应的场景,一切都是空谈.
不同场景下的不同架构实例

    秒杀架构演进
    架构1.如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面增加一个“定时上架”功能，仅在秒杀开始时才让用户看到购买按钮，当商品的库存卖完了也就结束了
    架构2.随着请求量的加大(比如从1w/s到了10w/s),这个简单的架构很快就遇到了瓶颈,因此需要做架构改造来提升系统性能.这些架构改造包括:
        1.把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化，例如这个独立出来的系统就减少了店铺装修的功能，减少了页面的复杂度；
        2.在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；
        3.将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；
        4.增加秒杀答题，防止有秒杀器抢单
    架构3.然而这个架构仍然支持不了超过 100w/s 的请求量，所以为了进一步提升秒杀系统的性能，我们又对架构做进一步升级
        1.对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少
        2.在服务端对秒杀商品进行本地缓存，不需要再调用依赖系统的后台服务获取数据，甚至不需要去公共的缓存集群中查询数据，这样不仅可以减少系统调用，而且能够避免压垮公共缓存集群
        3.增加系统限流保护，防止最坏情况发生            
架构2示意图
![image_22](../image_22.png)
架构3示意图
经过这些优化，系统架构变成了下图中的样子。在这里，我们对页面进行了进一步的静态化，秒杀过程中不需要刷新整个页面，而只需要向服务端请求很少的动态数据。而且，最关键的详情和交易系统都增加了本地缓存，来提前缓存秒杀商品的信息，热点数据库也做了独立部署，等等
![image_23](../image_23.png)


8.从性能角度上如何保证秒杀系统稳定?预热,削峰.减少数据库的访问,缓存

9.A B系统转账如何保证分布式数据一致性?

10.你有什么想问的?

11.ArrayList和LinkedList的区别

ArrayList是如何实现的?

    1.ArrayList实现类 
```java
public class ArrayList<E> extends AbstractList<E>
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable{
    
        //默认初始化容量
        private static final int DEFAULT_CAPACITY = 10;
        //对象数组
        transient Object[] elementData; 
        //数组长度
        private int size;
        
        }
```
        ArrayList 实现了 List 接口，继承了 AbstractList 抽象类，底层是数组实现的，并且实现了自增扩容数组大小。
        ArrayList 还实现了 Cloneable 接口和 Serializable 接口，所以他可以实现克隆和序列化。
        ArrayList 还实现了 RandomAccess 接口。你可能对这个接口比较陌生，不知道具体的用处。通过代码我们可以发现，
        这个接口其实是一个空接口，什么也没有实现，那 ArrayList 为什么要去实现它呢？
        其实 RandomAccess 接口是一个标志接口，他标志着“只要实现该接口的 List 类，都能实现快速随机访问”
    
    2.ArrayList属性
        ArrayList 属性主要由数组长度 size、对象数组 elementData、初始化容量 default_capacity 等组成， 其中初始化容
        量默认大小为 10。
        从 ArrayList 属性来看，它没有被任何的多线程关键字修饰，但 elementData 被关键字 transient 修饰了。这就是我在上
        面提到的第一道测试题：transient 关键字修饰该字段则表示该属性不会被序列化，但 ArrayList 其实是实现了序列化接口，
        这到底是怎么回事呢？
        由于 ArrayList 的数组是基于动态扩增的，所以并不是所有被分配的内存空间都存储了数据
        如果采用外部序列化法实现数组的序列化，会序列化整个数组。ArrayList 为了避免这些没有存储数据的内存空间被序列化，内部
        提供了两个私有方法 writeObject 以及 readObject 来自我完成序列化与反序列化，从而在序列化与反序列化数组时节省了空
        间和时间    
        因此使用 transient 修饰数组，是防止对象数组被其他外部方法序列化。


