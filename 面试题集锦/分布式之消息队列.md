分布式消息队列

1.为什么使用消息队列?使用消息队列的优势.
    业务场景,这个业务场景有什么技术挑战
    消息队列常见的三种核心使用场景:解耦 异步 削峰

    解耦:画图,假设A系统发送个数据到BCD三个系统,接口调用发送,那如果E系统也要这个数据?那如果C系统现在不需要了呢?A系统要时时刻刻
    考虑BCDE四个系统如果挂了怎么办?要不要重新调用接口?

    异步:降低延迟
    
    削峰:每天0点到11点,A系统风平浪静,每秒并发请求数量是100个,结果每次一到11点到1点,每秒请求数达到1万,但是系统最大出力能力每秒钟
    2000个,系统会被压垮.如果使用mq,可以将多余的消息暂时存起来,等到高峰期过后处理

2那你说说用消息队列都有什么优点和缺点? 优点:在特殊场景下有其对应的好处,解耦 异步 削峰 缺点:

    1.系统可用性降低,mq一旦故障,订阅系统将无法消费到消息,进而导致整个系统崩溃
    2.系统复杂度提高,系统A本来给系统B发一条数据就可以了,结果因为系统A和MQ之间协调出现问题,系统A不小心将同一条数据发送了2次给系统B,  
    导致系统B内部插入了2条一模一样的数据
    3.一致性问题:A系统处理完了直接返回成功了,用户以为成功了,但是问题是,要是BCD三个系统那里,BC两个系统写库成功了,结果C系统写库失败了,
    就会导致数据不一致问题

3.Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？

    选择中间件的考量维度:可靠性,性能,可运维性,可扩展性,是否开源以及社区活跃度
     rabbitmq
     优点:轻量,迅捷,容易部署和使用,拥有灵活的路由配置
     缺点:性能和吞吐量较差,基于erlang语言开发,不易进行二次开发
     rocketmq
     优点:性能好,稳定可靠,有活跃的中文社区,特点响应快
     缺点:兼容性较差,但随着影响力的扩大,该问题会改善
     kafka
     优点:拥有强大的性能及吞吐量,兼容性好
     缺点:由于攒一波再处理导致延迟比较高 

4.如何保证消息队列的高可用

5.如何保证消息不被重复消费

     1.消息重复的情况必然存在.这是因为在MQTT(消息队列遥测传输)协议中,给出了三种传递消息时能够提供的服务质量标准,这三种服务质量从低到高依次是
     At most once:至多一次.消息在传递时,最多会送达一次.换一个说法就是,没什么消息可靠性保证,允许丢消息.一般都是一些对消息可靠性要求不太高的
     监控场景使用,比如每分钟上报一次机房温度数据,可以接受数据少量丢失
     At least once:至少一次.消息在传递时,至少会被送达一次.也就是说,不允许丢消息,但是允许有少量重复消息存在.
     Exactly once:恰好一次.消息在传递时,只会被送达一次,不允许丢失也不允许重复.这个是最高的等级.
     这个服务质量标准不仅适用于MQTT,对所有的消息队列都是适用的.我们现在常用的绝大部分消息队列提供的服务质量都是At least once,包括
     RocketMQ RabbitMQ和kafka都是这样,也就是说很难保证消息不重复
     
     2.解决消息重复
     a.用幂等性解决重复消息问题(一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同).举个例子:
     在不考虑并发的情况下:"将账户的余额设置为100元",这是一个幂等操作.
     "将账户x的余额加100元",这个操作不是敏等的
     如果系统消费消息的业务逻辑具备幂等性,那就不用担心消息重复的问题,因为同一条消息,消费一次和消费多次对系统的影响是完全一样的.
     也就可以认为,消费多次等于消费一次.
     从对系统的影响结果来说:At least once + 幂等消费 = Exactly once
     那如何实现幂等操作呢?最好的方式就是从业务逻辑上入手,将消费的业务逻辑设计成具备幂等性的操作
     a1:利用数据库的唯一约束实现幂等.举个例子:"将账户x的余额增加100元",可以限定,对于每个转账单每个账户只可以执行一次变更操作.转账流水表:
     转账单id,账户id,变更金额,转账单id和账户id创建联合索引(生产者只要保证，发出去的每条转账消息都有一个唯一的转账单ID，这个“转账单 ID”可以存在生产者的数据库中，也可以不存，看业务需求。只要这个转账单ID不重复就可以了，这个很容易做到，比如我们用MySQL的Sequence就可以生成。
    消费者用这个转账单ID结合数据库（消费者的数据库，可以和生产者数据库不同）的唯一约束，就可以来实现消费幂等了。)这样对于相同的转账单id和账户id,表里至多只能存在一条记录
     a2:为更新的数据设置前置条件
     给数据增加一个版本号属性,每次更新数据前,比较当前数据的版本号是否和消息中的版本号一致,如果不一致就拒绝更新数据,如果一致,则更新数据的同时将版本号+1,一样可以实现幂等更新
     a3:记录并检查操作
     记录并检查操作,也称为"Token机制或者GUID(全局唯一id)机制",实现的思路特别简单:在执行数据更新操作之前,先检查一下是否执行过这个更新操作.
     具体的实现方法时,在发送消息时,给每条消息指定一个全局唯一的id,消费时,先根据这个id检查这条消息是否有被消费过,如果没有消费过,才更新数据,然后将消费状态置为已消费.
     在分布式系统中,这个方法其实是非常难以实现的,涉及到分布式事务和分布式锁

6.如何保证消息的可靠性传输?(如何处理消息丢失的问题)

    我们可以消息队列的有序性来验证是否有消息丢失.原理非常简单,在Producer端,我们给每个发出的消息附加一个连续递增的序号,  
    然后在Consumer端来检查这个序号的连续性.
    一条消息从生产到消费完成这个过程,可以划分为三个阶段
    在生产阶段:你需要捕获消息发送的错误,并重发消息
    [
        在生產阶段,消息队列通过最常用的请求确认机制,来保证消息的可靠传递:当你的代码调用发送消息方法时,消息队列的客户端
        会把消息发送Broker,Broker收到消息后,会给客户端返回一个确认响应,表明消息已经收到了.客户端收到响应后,完成了一次
        正常消息的发送.
        只要Producer收到了Broker的确认响应,就可以保证消息在生产阶段不会丢失.有些消息队列在长时间没收到发送确认响应后,
        会自动重试,如果重试再失败,就会议返回值或者抛出异常的方式告知用户
        你在编写发送消息代码时,需要注意,正确处理返回值或者捕获异常,就可以保证这个阶段的消息不会丢失.
        以kafka为例,看下如何可靠的发送消息

        try {
            RecordMetadata metadata = producer.send(record).get();
            System.out.println("消息发送成功。");
        } catch (Throwable e) {
            System.out.println("消息发送失败！");
            System.out.println(e);
        }
    
        异步发送时,则需要在回调方法里进行检查    
        producer.send(record, (metadata, exception) -> {
            if (metadata != null) {
                System.out.println("消息发送成功。");
            } else {
                System.out.println("消息发送失败！");
                System.out.println(exception);
            }
        });    
    ]

    在存储阶段:你可以通过配置刷盘和复制相关的参数,让消息写入到多个副本的磁盘上,来确保消息不会因为某个broker宕机,或者磁盘
    损坏而丢失.
    [
        在存储阶段正常情况下,只要broker在正常运行,就不会出现消息丢失的问题,但是如果Broker出现了故障,比如进程死掉了或者服务器
    宕机,还是可能会丢失消息的
    如果对消息的可靠性要求非常高,可以通过配置Broker参数来避免因为宕机丢失消息
       对于单个节点的Broker,需要配置Broker参数,在收到消息后,将消息写入磁盘后再给Producer返回确认机制,这样即使发生宕机,由于
    消息已经被写入磁盘,就不会丢失消息,恢复后还可以继续消费.在RocketMQ中,需要将双排方式FlushDiskType配置为SYNC_Flush同步刷盘
       如果是Broker是由多个节点组成的集群,需要将Broker集群配置成:至少将消息发送到2个以上的节点,再给客户端恢复发送确认响应.
    这样当某个Broker宕机时,其他的Broker可以替代宕机的Broker,也不会发生消息丢失            
    ]
      
    在消费阶段:你需要在处理完全部消费业务逻辑之后,再发送消费确认
    [
        消费阶段采用和生产阶段类似的确认机制来保证消息的可靠性,客户端从Broker拉取消息后,执行用户的消费业务逻辑,成功后,才会给Broker发送消费确认响应.
        如果Broker没有收到消费确认响应,下次拉消息的时候还会返回同一条消息,确保消息不会在网络传输过程中丢失,也不会因为客户端在执行消费逻辑中出错导致丢失.
        注意:不要在收到消息后就立即发送消费确认,而是应该在执行完成所有消费业务逻辑之后,再发送消费确认    
    ]

7.如何保证消息的顺序性?

    RocketMQ采用了局部顺序一致性的机制,实现单个队列中消息严格有序,也就是说,如果想要保证顺序消费,必须将一组消息发送到同一个队列找中,然后再由
    消费者进行顺序消费
    RocketMQ推荐的顺序消费解决方案是:按照业务划分不同的队列,然后将需要顺序消费的消息发往统一队列中即可.

8.消息积压了,该如何处理?

    第一种情况,消费速度慢于生产速度,靠扩充consumer实例
    
    使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果这种性
    能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。
    
    要是消费速度一直比生产速度慢，时间长了，整个系统就会出现问题，要么，消息队列的存储被填满无法提供服务，要么消息丢失，这对于
    整个系统来说都是严重故障。所以，我们在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康
    的持续运行        
    
    所以，我们在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。

    消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的一点是
    ，在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的
    。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。原因我们之前讲过，因为对于消费者来说，在每个分区上
    实际上只能支持单线程消费。
    
    第二种情况,突然积压消息靠监控
    
    还有一种消息积压的情况是，日常系统正常运转的时候，没有积压或者只有少量积压很快就消费掉了，但是某一个时刻，突然就开始积压消
    息并且积压持续上涨。这种情况下需要你在短时间内找到消息积压的原因，迅速解决问题才不至于影响业务。
    
    导致突然积压的原因肯定是多种多样的，不同的系统、不同的情况有不同的原因，不能一概而论。但是，我们排查消息积压原因，是有一些
    相对固定而且比较有效的方法的。能导致积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了。

    大部分消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。如果是单位时间发送的消息增多，比如说是赶上大促或
    者抢购，短时间内不太可能优化消费端的代码来提升消费性能，唯一的方法是通过扩容消费端的实例数来提升总体的消费能力。
    
    如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最
    低限度让系统还能正常运转，服务一些重要业务
    
    第三种情况:消费失败导致一条消息反复被消费,靠日志
    
    还有一种不太常见的情况，你通过监控发现，无论是发送消息的速度还是消费消息的速度和原来都没什么变化，这时候你需要检查一下你的
    消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。
    如果监控到消费变慢了，你需要检查你的消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没
    有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。

9.如何利用事务性消息实现分布式事务?

![image_18](../image_18.png)
    消息队列中的"事务",主要解决的是消息生产者和消息消费者的数据一致性问题
    1.发送Half消息
    2.Half消息发送成功
    3.执行本地事务
    4.提交或回滚事务
    5.网络异常，Broker没有收到commit or rollback，回查本地事务状态
    6.检查本地事务状态
    7.根据本地事务状态执行commit or rollback
    8.根据 4 或 7 投递消息到MQ订阅方，或者取消不投递

10.主题和队列的区别?
    1、主题（topic）中有多个队列（队列数量可以水平进行扩容），生产者将其消息发送给主题中的某个队列（根据一定的路由规则，比如  
    取模之类的），主题不保证消息的有序，只有队列中的消息才是有序的。
    2、从主题中的所有队列中取出消息给所有消费组进行消费，消息只能被消费组中的一个线程进行消费，有点类似线程池的形式，工作线程消  
    费来自不同队列的消息，感觉这也是RocketMq,低时延的原因，不同队列中的消息可以同时被消费，并且消费组的线程也可以并发的消费  
    不同的消息。
    3、由于主题中的一个队列都会被多个消费组进行消费，为此需要为每个消费组的消费的不同队列为此一个下标(每个消费组可以一直消费队  
    列中的消息，无需等待其他消费组的确认)，主题中的队列消息是有序的，为此需要等到所有消费组对此条消息进行确认，才能从队列中移除  
    ，感觉每个消费组的队列下标，可以一个队列维护一个CurrentHashMap来为此每个消费组的下标，这样的话可以防止锁的竞争。
    课后习题：尝试回答下课后习题，感觉队列可以维护一个全局的下标，消费队列时，使用CAS进行下标的获取，由于不保证消息消费的有序  
    ，这样的话可以并发的消费消息，由于有全局下标，不会出现获取队列的空洞消息。

11.如果让你写一个消息队列,该如何进行架构设计?说一下你的思路

    首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 
    kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，
    简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？

    其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？
    顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。
    
    其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader
     & follower -> broker 挂了重新选举 leader 即可对外服务。
    
    能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。

12.RocketMQ源码?

    发送消息
    消费消息
    RocketMQ 的消息是怎么写到文件里的？
